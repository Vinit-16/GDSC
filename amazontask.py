# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gCKVusEU1-8wHpds6tUkrVTwDdssAXs1
"""

import pandas as pd

import nltk

from nltk.sentiment.vader import SentimentIntensityAnalyzer

from nltk.corpus import stopwords

from nltk.tokenize import word_tokenize

from nltk.stem import WordNetLemmatizer

import nltk

nltk.download('all')

df = pd.read_csv("/content/amazon.csv")

df

def preprocess_text(text):

    tokens = word_tokenize(text.lower())

    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]


    lemmatizer = WordNetLemmatizer()

    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]


    processed_text = ' '.join(lemmatized_tokens)

    return processed_text


df['reviewText'] = df['reviewText'].apply(preprocess_text)
df

analyzer = SentimentIntensityAnalyzer()

def get_sentiment(text):

    scores = analyzer.polarity_scores(text)

    sentiment = 1 if scores['pos'] > 0 else 0

    return sentiment


df['sentiment'] = df['reviewText'].apply(get_sentiment)

df

from sklearn.metrics import confusion_matrix

print(confusion_matrix(df['Positive'], df['sentiment']))

from sklearn.metrics import classification_report

print(classification_report(df['Positive'], df['sentiment']))

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
accuracy = accuracy_score(df['Positive'], df['sentiment'])
precision = precision_score(df['Positive'], df['sentiment'], average='weighted')
recall = recall_score(df['Positive'], df['sentiment'], average='weighted')
f1 = f1_score(df['Positive'], df['sentiment'], average='weighted')

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')

